# Machine Learning 
___

By Warda Gull\
Computer Science Student\
University of South Asia

> This data is taken from my Instructor's slides and is only for educational purpose.

## Definition

![image](Extra\1.png)

## Types Of ML

![image](Extra\11.png)

### 1. Supervised Learning 

#### Regression

![image](Extra\3.png)

#### Classification

![image](Extra\4.png)

#### Types Of Classification

- Binary Classification:
Predicting whether an individual belongs to one class or another (Yes/No).
- Multiclass Classification: 
Predicting which of multiple classes the individual will belong to.


#### Algorithms of  Supervised Learning:

![image](Extra\12.png)

##### Simple Linear Regression (only for Numeric)

![image](Extra\17.png)

![image](Extra\18.png)

##### Multiple Linear Regression (only for Numeric)

![image](Extra\19.png)

### Decision Tree (For both Classification and numeric)

Probability/ Confidence based

![image](Extra\20.png)

**Assumption**: On which basis we choose an algorithm as linear Regression's assumptions are both variables are Numeric.

### K-Nearest Algorithm ( Mostly for Classification)

![image](Extra\21.png)
![image](Extra\22.png)

Can  be used in both classification and regression (by taking mean) but is mostly used in classification.

### SVM

SVM, or Support Vector Machine, is a smart tool that draws lines to separate different things or predict numbers. It's like drawing a line between boys and girls or guessing how many cookies you might sell at different times. Learning about SVM helps us make better decisions with data in the future.

### Kernal SVM

Think of kernel SVM as a special version of basic SVM. It uses a clever trick called a "kernel function" to change how the data looks, making it easier for SVM to understand tricky patterns, even ones that aren't in straight lines. This helps us get better results when dealing with more complex data.

### Naive  Bayes

Naive Bayes is a straightforward but effective machine learning algorithm for classification tasks. It makes a simple assumption that each feature contributes independently to the classification decision. This means it looks at each feature on its own to predict the category of data. This simplicity makes Naive Bayes easy to understand and remember for future reference.

### Random Forest Algorithm

Random Forest is a machine learning algorithm that helps us understand and classify data into different categories. It's like having a group of friends in a jungle, where each friend helps decide what type of fruit we're looking at by asking different questions, like "Is it red?" or "Is it big?" Then, we combine everyone's answers to figure out what the fruit is. So, Random Forest is like a helpful team of decision-makers in the jungle of data.

### Evaluation Metrics 

Every ML Model must have to be evaluate how much percent it  can predict correctly. It is known as Evaluation Metrics.

**Evaluation Metrics for Classification**\
- Accuracy
- Precision
- Recall (Sensitivity)
- F1 Score
- ROC-AUC (Receiver Operating Characteristic - Area Under Curve)

**Evaluation Metrics for  Regression**

- Mean Absolute Error (MAE)
- Mean Squared Error (MSE)
- Root Mean Squared Error (RMSE)
- R-squared (R2)
- Mean Absolute Percentage Error (MAPE)

![image](Extra\23.png)













### 2. Unspervised Learning 

#### Clustering

![image](Extra\5.png)

#### Algorithms

![image](Extra\13.png)

### 3. Semi-Supervised Learning

![image](Extra\6.png)

### 4. Reinforcement Learning

![image](Extra\7.png)

![alt text](image-2.png)

## ML Model

![image](Extra\9.png)

## Important libraies for ML

1. Scikit-learn
2. Tensorflow(with Keras)
3. Pytorch

### How scikit-learn works

![image](Extra\15.png)

x is directly proportional to y

#### Model training

![image](Extra\16.png)









